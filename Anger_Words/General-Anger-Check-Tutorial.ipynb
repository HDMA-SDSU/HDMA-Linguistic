{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following tutorial shows how the anger words can be applied to identifying anger in general Twitter data. Here, we count tweets containing at least one of the anger words in data collected in San Diego during the 2018 State of the Union."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from cytoolz import concat\n",
    "import re\n",
    "import os\n",
    "\n",
    "def anger_(l):\n",
    "    x = [w for w in re.findall(r'\\bliar\\b|\\bliars\\b|\\blying\\b|\\blies\\b|\\bhypocrite\\b|\\bhypocrites\\b|\\bhypocrisy\\b|\\bhypocritical\\b|\\basshole\\b|\\bassholes\\b|\\bbullshit\\b|\\bdisgrace\\b|\\bdisgraces\\b|\\bdisgraced\\b|\\bdisgraceful\\b|\\bstfu\\b|\\bdisgusting\\b|\\bdisgusted\\b|\\bdisgusts\\b|\\bscum\\b|\\binfuriate\\b|\\binfuriates\\b|\\binfuriating',l)]\n",
    "    a = [w for w in re.findall(r'\\bfuck you\\b|\\bthe fuck up\\b|\\bpiece of shit\\b|\\bgo fuck yourself\\b',l)]\n",
    "    b = [w for w in re.findall(r'\\b(piss)\\b.*off',l)]\n",
    "    c = [w for w in re.findall(r'\\boff\\b.*\\b(piss)\\b',l)]\n",
    "    d = [w for w in re.findall(r'\\b(fuck)\\b.*\\boff\\b',l)]\n",
    "    e = [w for w in re.findall(r'\\boff\\b.*\\b(fuck)\\b',l)]\n",
    "    z = []\n",
    "    lists = [x,a,b,c,d,e,]\n",
    "    for q in lists:\n",
    "        for s in q:\n",
    "            z.append(s)\n",
    "    return z\n",
    "\n",
    "#Count occurrences of anger words\n",
    "def angertopic(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['bow'] = df['TEXT'].str.lower().str.replace(r'(https?://.+|[^\\w#@]+|\\d+)+',' ').str.split()\n",
    "    df = df[df['bow'].isnull()==False]\n",
    "    df['anger words'] = df['TEXT'].str.lower().apply(anger_)\n",
    "    words = list(concat(df['anger words']))\n",
    "    wordcounts = Counter(words)\n",
    "    if wordcounts == Counter():\n",
    "        dic = {'Anger Words': 0, 'Tweet Count': len(df)}\n",
    "        counts = pd.DataFrame.from_dict(dic,orient='index')\n",
    "        counts.columns = ['Count']\n",
    "    else:\n",
    "        keywords = {'liar':0, 'liars':0,'lying':0, 'lies':0, \n",
    "                'hypocrite':0,'hypocrites':0, 'hypocrisy':0, 'hypocritical':0,\n",
    "                'asshole':0, 'assholes':0, 'bullshit':0, \n",
    "                'fuck':0, 'fuck you':0, \n",
    "                'disgrace':0, 'disgraces':0, 'disgraced':0, 'disgraceful':0, \n",
    "                'piece of shit':0, 'the fuck up':0, \n",
    "                'piss':0, 'stfu':0,\n",
    "                'disgusting':0, 'disgusted':0, 'disgusts':0, \n",
    "                'go fuck yourself':0, 'scum':0, \n",
    "                'infuriate':0, 'infuriates':0, 'infuriating':0, 'infuriated':0}\n",
    "        kw = pd.DataFrame.from_dict(keywords, orient='index')\n",
    "        wc = pd.DataFrame.from_dict(wordcounts, orient='index')\n",
    "        counts = kw.join(wc, how='left', lsuffix = 'kw', rsuffix = 'wc').fillna(0)\n",
    "        counts['Counts'] = counts['0kw'] + counts['0wc']\n",
    "        del counts['0kw']\n",
    "        del counts['0wc']\n",
    "        if 'fuck' in counts.index:\n",
    "            counts.index.set_value(counts.index, 'fuck', 'fuck off')\n",
    "        if 'piss' in counts.index:\n",
    "            counts.index.set_value(counts.index, 'piss', 'piss(ed) off')\n",
    "        counts.loc['~Total'] = counts.sum()\n",
    "        counts.loc['~Tweet Count'] = len(df)\n",
    "        counts['Percent'] = (counts['Counts']/len(df))*100\n",
    "    print(counts.sort_index(axis=0, ascending=True))\n",
    "\n",
    "def angertopics(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            angertopic(os.path.join(directory, filename))\n",
    "            continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The next cell shows what the data looks like. The only required fields for this code are the TEXT column, which has one tweet per cell. Note that this is case sensitive, so the column must be called TEXT (not 'text' or 'Text').\n",
    "\n",
    "We recommend filtering data to English tweets only and removing retweets, which can be done by adding to the available code or by preprocessing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GEOCODING TYPE</th>\n",
       "      <th>TWEET_ID</th>\n",
       "      <th>KEYWORD</th>\n",
       "      <th>CITY</th>\n",
       "      <th>CREATED_AT</th>\n",
       "      <th>CREATED_AT_LOCAL</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FROM_USER</th>\n",
       "      <th>FROM_USER_NAME</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>...</th>\n",
       "      <th>TO_USER_NAME</th>\n",
       "      <th>IN_REPLY_TO_STATUS_ID</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>IS_VALID_ONLY_FOR_FLU</th>\n",
       "      <th>GEOCODE_ENGINE</th>\n",
       "      <th>GEOCODE_TYPE</th>\n",
       "      <th>PROFILE_GEO</th>\n",
       "      <th>PROFILE_LEVEL</th>\n",
       "      <th>FINAL_GEO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Location</td>\n",
       "      <td>9.600000e+17</td>\n",
       "      <td>sotu</td>\n",
       "      <td>San_Diego</td>\n",
       "      <td>2/3/18 7:57</td>\n",
       "      <td>2/2/18 23:57</td>\n",
       "      <td>@RepMattGaetz This from a guy who has been arr...</td>\n",
       "      <td>CounterSocial66</td>\n",
       "      <td>Teddy Pendergrass</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>HDMA</td>\n",
       "      <td>userProfile</td>\n",
       "      <td>-116.77021,33.0282</td>\n",
       "      <td>undefined</td>\n",
       "      <td>-116.77021, 33.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Location</td>\n",
       "      <td>9.600000e+17</td>\n",
       "      <td>state of the union</td>\n",
       "      <td>San_Diego</td>\n",
       "      <td>2/3/18 7:27</td>\n",
       "      <td>2/2/18 23:27</td>\n",
       "      <td>A new poll from NBC News released on Thursday ...</td>\n",
       "      <td>Enciniman1</td>\n",
       "      <td>James Parr</td>\n",
       "      <td>Encinitas, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>HDMA</td>\n",
       "      <td>userProfile</td>\n",
       "      <td>-117.29198,33.03699</td>\n",
       "      <td>undefined</td>\n",
       "      <td>-117.29198, 33.03699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Location</td>\n",
       "      <td>9.600000e+17</td>\n",
       "      <td>sotu</td>\n",
       "      <td>San_Diego</td>\n",
       "      <td>2/3/18 7:17</td>\n",
       "      <td>2/2/18 23:17</td>\n",
       "      <td>@realDonaldTrump Wow... The idiot he retweeted...</td>\n",
       "      <td>MFooteOBSDbeer</td>\n",
       "      <td>Michelle Foote</td>\n",
       "      <td>Ocean Beach, San Diego, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Place</td>\n",
       "      <td>9.600000e+17</td>\n",
       "      <td>sotu</td>\n",
       "      <td>San_Diego</td>\n",
       "      <td>2/3/18 5:41</td>\n",
       "      <td>2/2/18 21:41</td>\n",
       "      <td>@tedlieu @realDonaldTrump @FBI I didn't read e...</td>\n",
       "      <td>ZangerJames</td>\n",
       "      <td>James Zanger</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-117.10498915,32.8100122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Location</td>\n",
       "      <td>9.600000e+17</td>\n",
       "      <td>state of the union</td>\n",
       "      <td>San_Diego</td>\n",
       "      <td>2/3/18 4:31</td>\n",
       "      <td>2/2/18 20:31</td>\n",
       "      <td>Nancy Pelosi  As a citizen of the State of Cal...</td>\n",
       "      <td>KathyCazin</td>\n",
       "      <td>Kathy Cazin</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>HDMA</td>\n",
       "      <td>userProfile</td>\n",
       "      <td>-116.77021,33.0282</td>\n",
       "      <td>undefined</td>\n",
       "      <td>-116.77021, 33.0282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  GEOCODING TYPE      TWEET_ID             KEYWORD       CITY   CREATED_AT  \\\n",
       "0       Location  9.600000e+17                sotu  San_Diego  2/3/18 7:57   \n",
       "1       Location  9.600000e+17  state of the union  San_Diego  2/3/18 7:27   \n",
       "2       Location  9.600000e+17                sotu  San_Diego  2/3/18 7:17   \n",
       "3          Place  9.600000e+17                sotu  San_Diego  2/3/18 5:41   \n",
       "4       Location  9.600000e+17  state of the union  San_Diego  2/3/18 4:31   \n",
       "\n",
       "  CREATED_AT_LOCAL                                               TEXT  \\\n",
       "0     2/2/18 23:57  @RepMattGaetz This from a guy who has been arr...   \n",
       "1     2/2/18 23:27  A new poll from NBC News released on Thursday ...   \n",
       "2     2/2/18 23:17  @realDonaldTrump Wow... The idiot he retweeted...   \n",
       "3     2/2/18 21:41  @tedlieu @realDonaldTrump @FBI I didn't read e...   \n",
       "4     2/2/18 20:31  Nancy Pelosi  As a citizen of the State of Cal...   \n",
       "\n",
       "         FROM_USER     FROM_USER_NAME                    LOCATION  \\\n",
       "0  CounterSocial66  Teddy Pendergrass               San Diego, CA   \n",
       "1       Enciniman1         James Parr               Encinitas, CA   \n",
       "2   MFooteOBSDbeer     Michelle Foote  Ocean Beach, San Diego, CA   \n",
       "3      ZangerJames       James Zanger               San Diego, CA   \n",
       "4       KathyCazin        Kathy Cazin               San Diego, CA   \n",
       "\n",
       "             ...            TO_USER_NAME IN_REPLY_TO_STATUS_ID  \\\n",
       "0            ...                     NaN                   NaN   \n",
       "1            ...                     NaN                   NaN   \n",
       "2            ...                     NaN                   NaN   \n",
       "3            ...                     NaN                   NaN   \n",
       "4            ...                     NaN                   NaN   \n",
       "\n",
       "                SOURCE LANGUAGE IS_VALID_ONLY_FOR_FLU  GEOCODE_ENGINE  \\\n",
       "0     Twitter for iPad       en                 False            HDMA   \n",
       "1  Twitter for Android       en                 False            HDMA   \n",
       "2  Twitter for Android       en                 False             NaN   \n",
       "3  Twitter for Android       en                 False             NaN   \n",
       "4   Twitter Web Client       en                 False            HDMA   \n",
       "\n",
       "  GEOCODE_TYPE          PROFILE_GEO  PROFILE_LEVEL                 FINAL_GEO  \n",
       "0  userProfile   -116.77021,33.0282      undefined       -116.77021, 33.0282  \n",
       "1  userProfile  -117.29198,33.03699      undefined      -117.29198, 33.03699  \n",
       "2          NaN                  NaN            NaN                       NaN  \n",
       "3          NaN                  NaN            NaN  -117.10498915,32.8100122  \n",
       "4  userProfile   -116.77021,33.0282      undefined       -116.77021, 33.0282  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/HDMA-SDSU/HDMA-Linguistic/master/Anger_Words/Data/2018%20State%20of%20the%20Union%20cut.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here, the anger check code is applied using the angertopic function. In this tutorial, data is read from a URL. When you apply this to your own data using the Gener-Anger-Check notebook (https://github.com/HDMA-SDSU/HDMA-Linguistic/blob/master/Anger_Words/General-Anger-Check.ipynb), data will be loaded from your computer by typing the path to the file on your computer, e.g. angertopic('/Users/ilana/Anger/data.xlsx')\n",
    "\n",
    "For the tutorial, the results are printed in this notebook. When using the General-Anger-Check notebook, data will be exported to your computer as a CSV file in the same format shown here. The resulting file will be called [original file name] anger.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Counts     Percent\n",
      "asshole              0.0    0.000000\n",
      "assholes             0.0    0.000000\n",
      "bullshit             5.0    0.333333\n",
      "disgrace             6.0    0.400000\n",
      "disgraced            1.0    0.066667\n",
      "disgraceful          8.0    0.533333\n",
      "disgraces            0.0    0.000000\n",
      "disgusted            4.0    0.266667\n",
      "disgusting           8.0    0.533333\n",
      "disgusts             0.0    0.000000\n",
      "fuck off             0.0    0.000000\n",
      "fuck you             1.0    0.066667\n",
      "go fuck yourself     0.0    0.000000\n",
      "hypocrisy            0.0    0.000000\n",
      "hypocrite            0.0    0.000000\n",
      "hypocrites           0.0    0.000000\n",
      "hypocritical         0.0    0.000000\n",
      "infuriate            0.0    0.000000\n",
      "infuriated           0.0    0.000000\n",
      "infuriates           0.0    0.000000\n",
      "infuriating          0.0    0.000000\n",
      "liar                16.0    1.066667\n",
      "liars                0.0    0.000000\n",
      "lies                22.0    1.466667\n",
      "lying               15.0    1.000000\n",
      "piece of shit        0.0    0.000000\n",
      "piss(ed) off         0.0    0.000000\n",
      "scum                 0.0    0.000000\n",
      "stfu                 2.0    0.133333\n",
      "the fuck up          1.0    0.066667\n",
      "~Total              89.0    5.933333\n",
      "~Tweet Count      1500.0  100.000000\n"
     ]
    }
   ],
   "source": [
    "angertopic('https://raw.githubusercontent.com/HDMA-SDSU/HDMA-Linguistic/master/Anger_Words/Data/2018%20State%20of%20the%20Union%20cut.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first column shows all of the anger words, as well as the total number of anger words (~Total) and the total number of tweets (~Tweet Count). The second column shows the number of occurrences of each keyword, and the third column shows the anger word occurrences as a percentage of the total number of tweets. Note that these are percentages out of 100%, not decimals (i.e. 0.27 means 0.27%, not 27%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the Anger Words Technical Document (https://github.com/HDMA-SDSU/HDMA-Linguistic/blob/master/Anger_Words/Anger-Words-Technical-Doc.pdf) for more detailed explanation and instructions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
